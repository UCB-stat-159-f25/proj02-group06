{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3975c8d7-f042-456f-a92b-5f39b726b461",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e55d926-69e4-4ed4-bc79-1f70a5aba4c4",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73891963-5314-4809-94cb-97a926fe902e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8e6122-9f06-46fd-a280-73ace2072cc6",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "from spacy import displacy\n",
    "from bertopic import BERTopic\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pyLDAvis.gensim_models\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "plt.style.use('seaborn-v0_8-dark') \n",
    "\n",
    "sou = pd.read_csv('data/SOTU.csv')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_text(text): \n",
    "    doc = nlp(text) \n",
    "    return [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space and len(token.lemma_) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde44de3-6093-4e52-a9bf-7bbbddc40dec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process all texts - note this takes ~ 5 minutes to run\n",
    "processed_docs = sou['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d4298e-bc24-4bd1-84f9-872c6957f6f5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build dictionary from processed_docs, which is a list of tokens extracted from our speeches\n",
    "dic = Dictionary(processed_docs)\n",
    "dic.filter_extremes(no_below=5, no_above=0.5)\n",
    "corpus = [dic.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb500a5-6a09-43bf-a5ac-934f96173b3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train LDA model with 18 topics\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dic,\n",
    "    num_topics=18,\n",
    "    random_state=42,\n",
    "    passes=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc9db8f0-abb5-47f6-bcaa-4f90c5262148",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LDA Topics ---\n",
      "Topic: 0 \n",
      "Words: 0.004*\"cent\" + 0.004*\"june\" + 0.004*\"gold\" + 0.003*\"island\" + 0.003*\"silver\" + 0.003*\"bond\" + 0.003*\"method\" + 0.003*\"convention\" + 0.003*\"indian\" + 0.003*\"note\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.008*\"depression\" + 0.007*\"program\" + 0.007*\"recovery\" + 0.006*\"budget\" + 0.006*\"unemployment\" + 0.006*\"loan\" + 0.006*\"activity\" + 0.006*\"farm\" + 0.005*\"emergency\" + 0.005*\"cent\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.008*\"dictator\" + 0.005*\"expression\" + 0.004*\"british\" + 0.004*\"1914\" + 0.003*\"impressive\" + 0.003*\"actual\" + 0.003*\"revolution\" + 0.003*\"schedule\" + 0.003*\"continent\" + 0.003*\"partisanship\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.008*\"forest\" + 0.007*\"corporation\" + 0.005*\"judge\" + 0.005*\"wrong\" + 0.005*\"interstate\" + 0.004*\"employee\" + 0.003*\"bureau\" + 0.003*\"body\" + 0.003*\"mountain\" + 0.003*\"island\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.017*\"program\" + 0.014*\"soviet\" + 0.009*\"1980\" + 0.009*\"u.s.\" + 0.008*\"area\" + 0.007*\"major\" + 0.006*\"goal\" + 0.006*\"commitment\" + 0.006*\"challenge\" + 0.006*\"nuclear\"\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.015*\"americans\" + 0.014*\"tonight\" + 0.007*\"thank\" + 0.007*\"today\" + 0.007*\"budget\" + 0.006*\"hard\" + 0.005*\"program\" + 0.005*\"worker\" + 0.005*\"deficit\" + 0.005*\"challenge\"\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.004*\"minister\" + 0.004*\"british\" + 0.004*\"intercourse\" + 0.003*\"tribe\" + 0.003*\"france\" + 0.003*\"article\" + 0.003*\"indians\" + 0.003*\"spain\" + 0.003*\"convention\" + 0.003*\"deem\"\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.019*\"program\" + 0.008*\"billion\" + 0.007*\"budget\" + 0.006*\"today\" + 0.006*\"inflation\" + 0.005*\"americans\" + 0.005*\"percent\" + 0.004*\"major\" + 0.004*\"area\" + 0.004*\"farm\"\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.006*\"method\" + 0.004*\"railroad\" + 0.004*\"conference\" + 0.004*\"board\" + 0.004*\"farmer\" + 0.004*\"interstate\" + 0.004*\"agricultural\" + 0.003*\"industrial\" + 0.003*\"corporation\" + 0.003*\"cent\"\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.006*\"corporation\" + 0.006*\"tariff\" + 0.005*\"industrial\" + 0.005*\"evil\" + 0.004*\"combination\" + 0.004*\"island\" + 0.004*\"merely\" + 0.004*\"forest\" + 0.004*\"interstate\" + 0.004*\"farmer\"\n",
      "\n",
      "Topic: 10 \n",
      "Words: 0.001*\"program\" + 0.001*\"americans\" + 0.001*\"mexico\" + 0.001*\"june\" + 0.001*\"gold\" + 0.001*\"minister\" + 0.001*\"convention\" + 0.001*\"tonight\" + 0.001*\"company\" + 0.001*\"island\"\n",
      "\n",
      "Topic: 11 \n",
      "Words: 0.014*\"americans\" + 0.009*\"tonight\" + 0.007*\"percent\" + 0.007*\"thank\" + 0.006*\"worker\" + 0.006*\"iraq\" + 0.006*\"democracy\" + 0.005*\"fight\" + 0.005*\"terrorist\" + 0.005*\"challenge\"\n",
      "\n",
      "Topic: 12 \n",
      "Words: 0.017*\"program\" + 0.009*\"billion\" + 0.008*\"1947\" + 0.007*\"nations\" + 0.007*\"1946\" + 0.006*\"fight\" + 0.006*\"soviet\" + 0.006*\"housing\" + 0.006*\"communist\" + 0.005*\"1945\"\n",
      "\n",
      "Topic: 13 \n",
      "Words: 0.006*\"june\" + 0.006*\"convention\" + 0.005*\"slave\" + 0.005*\"slavery\" + 0.004*\"mexico\" + 0.004*\"kansas\" + 0.004*\"article\" + 0.004*\"minister\" + 0.004*\"election\" + 0.004*\"spain\"\n",
      "\n",
      "Topic: 14 \n",
      "Words: 0.015*\"weapon\" + 0.014*\"terrorist\" + 0.010*\"iraq\" + 0.009*\"americans\" + 0.009*\"saddam\" + 0.009*\"regime\" + 0.008*\"hussein\" + 0.008*\"terror\" + 0.007*\"threat\" + 0.007*\"drug\"\n",
      "\n",
      "Topic: 15 \n",
      "Words: 0.014*\"article\" + 0.012*\"manufacture\" + 0.011*\"port\" + 0.007*\"spain\" + 0.006*\"colony\" + 0.006*\"appoint\" + 0.006*\"admit\" + 0.006*\"france\" + 0.005*\"likewise\" + 0.005*\"presume\"\n",
      "\n",
      "Topic: 16 \n",
      "Words: 0.003*\"mexico\" + 0.002*\"texas\" + 0.001*\"convention\" + 0.001*\"minister\" + 0.001*\"indian\" + 0.001*\"june\" + 0.001*\"program\" + 0.001*\"mexican\" + 0.001*\"article\" + 0.001*\"british\"\n",
      "\n",
      "Topic: 17 \n",
      "Words: 0.023*\"mexico\" + 0.010*\"texas\" + 0.007*\"mexican\" + 0.004*\"minister\" + 0.004*\"currency\" + 0.004*\"article\" + 0.004*\"paper\" + 0.003*\"california\" + 0.003*\"oregon\" + 0.003*\"enemy\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the top 10 words for each topic\n",
    "print(\"\\n--- LDA Topics ---\") \n",
    "for idx, topic in lda_model.print_topics(-1): \n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02477e09-9df5-49d8-9749-762f4f3a6934",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, np.float32(0.99942815))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the topic distribution for the first speech\n",
    "lda_model.get_document_topics(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "811e1d56-be6d-4108-8153-0ad1dc791ad7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a visualization using pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "lda_display = pyLDAvis.gensim_models.prepare(lda_model, corpus, dic)\n",
    "pyLDAvis.display(lda_display)\n",
    "pyLDAvis.save_html(lda_display, 'outputs/lda_visualization.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89feeb16-4fa8-4460-b2be-78f039d22577",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6da06-4629-48dc-b629-925967b78dde",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sotu)",
   "language": "python",
   "name": "notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
