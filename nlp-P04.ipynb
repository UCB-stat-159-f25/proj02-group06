{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a773f4-507d-4e39-9af9-7b3e1aa8452b",
   "metadata": {},
   "source": [
    "# Part 4: Choose your own adventure! \n",
    "\n",
    "\n",
    "(7 Points; Optional for Extra Credit)\n",
    "\n",
    "This section is open ended and your chance to explare any advanced analysis. Please perform any additional analysis you find interesting! Suggested analyses (only do one max):\n",
    "\n",
    "Topic evolution over time - see https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization\n",
    "\n",
    "Word frequency over time - does the frequency of certain words change over time\n",
    "\n",
    "Semantic similarity - investigate similarity within and between presidents or time periods. For example, similarity between one presidents speeches, e.g. are all of Biden’s speeches similar to each other? How similar are they to Trump’s speeches? Are speeches from the 2000s more similar to each other than speeches in the 1800s? Which two presidents have the most similar speeches? See https://spacy.io/usage/linguistic-features#vectors-similarity\n",
    "\n",
    "Named Entity Recognition - which entity types are most common in speeches? What are the most common words for each entity type - see https://spacy.io/usage/linguistic-features#named-entities\n",
    "\n",
    "Classification - can you build a classifier to detect democratic versus republican state of the union speeches from 1980-2024 - see https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23edabe8-3290-4554-8f4b-326bfc7b7b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7cab69b-d68d-4988-9803-0b02821e082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# read in data\n",
    "sotu = pd.read_csv('data/SOTU.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23fffe05-03d3-46f0-9ce4-129d072736d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President</th>\n",
       "      <th>Year</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>\\n[Before speaking, the President presented hi...</td>\n",
       "      <td>8003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>\\nThe President. Mr. Speaker——\\n[At this point...</td>\n",
       "      <td>8978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>\\nThe President. Thank you all very, very much...</td>\n",
       "      <td>7539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>\\nThe President. Thank you. Thank you. Thank y...</td>\n",
       "      <td>7734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>\\nThe President. Thank you very much. Thank yo...</td>\n",
       "      <td>6169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>\\nFellow-Citizens of the Senate and House of R...</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>\\nFellow-Citizens of the Senate and House of R...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>\\nFellow-Citizens of the Senate and House of R...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>\\nFellow-Citizens of the Senate and House of R...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>\\nFellow-Citizens of the Senate and House of R...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             President    Year  \\\n",
       "0      Joseph R. Biden  2024.0   \n",
       "1      Joseph R. Biden  2023.0   \n",
       "2      Joseph R. Biden  2022.0   \n",
       "3      Joseph R. Biden  2021.0   \n",
       "4      Donald J. Trump  2020.0   \n",
       "..                 ...     ...   \n",
       "241  George Washington  1791.0   \n",
       "242  George Washington  1790.0   \n",
       "243  George Washington  1790.0   \n",
       "244  George Washington  1790.0   \n",
       "245  George Washington  1790.0   \n",
       "\n",
       "                                                  Text  Word Count  \n",
       "0    \\n[Before speaking, the President presented hi...        8003  \n",
       "1    \\nThe President. Mr. Speaker——\\n[At this point...        8978  \n",
       "2    \\nThe President. Thank you all very, very much...        7539  \n",
       "3    \\nThe President. Thank you. Thank you. Thank y...        7734  \n",
       "4    \\nThe President. Thank you very much. Thank yo...        6169  \n",
       "..                                                 ...         ...  \n",
       "241  \\nFellow-Citizens of the Senate and House of R...        2264  \n",
       "242  \\nFellow-Citizens of the Senate and House of R...        1069  \n",
       "243  \\nFellow-Citizens of the Senate and House of R...        1069  \n",
       "244  \\nFellow-Citizens of the Senate and House of R...        1069  \n",
       "245  \\nFellow-Citizens of the Senate and House of R...        1069  \n",
       "\n",
       "[246 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sotu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e23668e1-5f6c-45fd-a23c-3feb7ee2b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess text to clean for lemmas\n",
    "def preprocess_text(text): \n",
    "    doc = nlp(text) \n",
    "    return [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space and len(token.lemma_) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f8de4a-3b43-45eb-8f78-696c58113b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text and keep president info\n",
    "sotu['processed_text'] = sotu['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a09cd3aa-5746-40c5-8869-67520705ee21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2348/735472521.py:26: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity_matrix[i, j] = docs[i].similarity(docs[j])\n"
     ]
    }
   ],
   "source": [
    "# Build of list of each president\n",
    "presidents = sotu['President'].unique()\n",
    "\n",
    "# Append the lemmas of each presidents' speeches into one long string for each president\n",
    "# Keep name of president with string of text\n",
    "# This builds a dictionary of all speeches called combined_speeches\n",
    "combined_speeches = {\n",
    "    p: \" \".join([\" \".join(doc) for doc in sotu[sotu['President'] == p]['processed_text']])\n",
    "    for p in presidents\n",
    "}\n",
    "\n",
    "# Convert to lists\n",
    "names = list(combined_speeches.keys())            # Keys are presidents' names\n",
    "texts = list(combined_speeches.values())          # corresponding speech list of each president\n",
    "\n",
    "# Turn texts into spaCy docs\n",
    "docs = [nlp(text) for text in texts]\n",
    "\n",
    "# create a similarity matrix\n",
    "n = len(docs)\n",
    "\n",
    "similarity_matrix = np.zeros((n, n))  # initialize\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        similarity_matrix[i, j] = docs[i].similarity(docs[j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf5734-c782-408d-a1c7-a8233ea3a555",
   "metadata": {},
   "source": [
    "I chose to hide the diagonal as this is where each presidents' speeches are compared to their own so that would be disregarded when looking for the most similar presidents' speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a6538c-7a27-4071-abb6-9a7055d1f8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.99640006, 0.99574405, ..., 0.9859761 , 0.99067962,\n",
       "        0.98598027],\n",
       "       [0.99640006, 0.        , 0.99003059, ..., 0.98297691, 0.99239999,\n",
       "        0.98647565],\n",
       "       [0.99574405, 0.99003059, 0.        , ..., 0.99360591, 0.99029672,\n",
       "        0.99022341],\n",
       "       ...,\n",
       "       [0.9859761 , 0.98297691, 0.99360591, ..., 0.        , 0.99268615,\n",
       "        0.9971866 ],\n",
       "       [0.99067962, 0.99239999, 0.99029672, ..., 0.99268615, 0.        ,\n",
       "        0.99722457],\n",
       "       [0.98598027, 0.98647565, 0.99022341, ..., 0.9971866 , 0.99722457,\n",
       "        0.        ]], shape=(43, 43))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fill_diagonal(similarity_matrix, 0)\n",
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c60290f-ed1f-46be-881b-18683a38f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(22, 23), (23, 22)]\n"
     ]
    }
   ],
   "source": [
    "# extract the most similar pairs\n",
    "rows, cols = np.where(similarity_matrix == similarity_matrix.max())\n",
    "# turn into (,) format\n",
    "pairs = list(zip(rows, cols))\n",
    "pairs_int = [(int(a), int(b)) for a, b in pairs]\n",
    "print(pairs_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ae9f3d1-f44c-431c-a7fa-40977d81c868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar speeches were delivered by Grover Cleveland and Benjamin Harrison\n"
     ]
    }
   ],
   "source": [
    "# pairs_int[0] is the most similar pair\n",
    "i, j = pairs_int[0]  # unpack the tuple\n",
    "\n",
    "print(\"The most similar speeches were delivered by \" + names[i] + \" and \" + names[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee3fb0-7393-4f85-96e1-a84f42ad4947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sotu)",
   "language": "python",
   "name": "sotu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
